{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c32691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14566/2987543011.py:106: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  created = datetime.utcfromtimestamp(int(obj['created_utc']))\n",
      "2013-12-24 21:42:14 : 100,000 : 0 : 2%\n",
      "2014-01-02 21:48:00 : 200,000 : 0 : 2%\n",
      "2014-01-15 20:47:25 : 300,000 : 0 : 4%\n",
      "2014-01-22 07:34:34 : 400,000 : 0 : 4%\n",
      "2014-01-26 09:21:42 : 500,000 : 0 : 6%\n",
      "2014-01-30 12:39:30 : 600,000 : 0 : 6%\n",
      "2014-02-03 16:07:22 : 700,000 : 0 : 6%\n",
      "2014-02-07 23:20:19 : 800,000 : 0 : 8%\n",
      "2014-02-12 15:19:49 : 900,000 : 0 : 8%\n",
      "2014-02-16 00:46:17 : 1,000,000 : 0 : 11%\n",
      "2014-02-20 18:45:45 : 1,100,000 : 0 : 11%\n",
      "2014-02-27 17:04:09 : 1,200,000 : 0 : 11%\n",
      "2014-03-07 14:47:27 : 1,300,000 : 0 : 13%\n",
      "2014-03-17 06:12:07 : 1,400,000 : 0 : 13%\n",
      "2014-03-26 22:48:01 : 1,500,000 : 0 : 15%\n",
      "2014-04-04 03:02:49 : 1,600,000 : 0 : 15%\n",
      "2014-04-10 16:22:26 : 1,700,000 : 0 : 15%\n",
      "2014-04-16 04:27:48 : 1,800,000 : 0 : 17%\n",
      "2014-04-21 20:01:39 : 1,900,000 : 0 : 17%\n",
      "2014-04-28 21:46:42 : 2,000,000 : 0 : 19%\n",
      "2014-05-04 18:08:00 : 2,100,000 : 0 : 19%\n",
      "2014-05-10 22:38:14 : 2,200,000 : 0 : 19%\n",
      "2014-05-17 01:11:28 : 2,300,000 : 0 : 21%\n",
      "2014-05-23 13:22:07 : 2,400,000 : 0 : 21%\n",
      "2014-05-30 12:32:51 : 2,500,000 : 0 : 23%\n",
      "2014-06-09 01:55:44 : 2,600,000 : 0 : 23%\n",
      "2014-06-26 20:03:56 : 2,700,000 : 0 : 25%\n",
      "2014-07-17 14:17:37 : 2,800,000 : 0 : 25%\n",
      "2014-08-12 13:08:50 : 2,900,000 : 0 : 25%\n",
      "2014-09-15 13:55:08 : 3,000,000 : 0 : 27%\n",
      "2014-10-20 14:01:48 : 3,100,000 : 0 : 27%\n",
      "2014-11-24 13:32:12 : 3,200,000 : 0 : 29%\n",
      "2015-01-18 15:23:43 : 3,300,000 : 0 : 29%\n",
      "2015-05-08 14:37:22 : 3,400,000 : 0 : 29%\n",
      "2016-01-09 17:28:32 : 3,500,000 : 0 : 31%\n",
      "2017-06-13 22:45:22 : 3,600,000 : 0 : 31%\n",
      "2018-01-14 20:25:03 : 3,700,000 : 0 : 32%\n",
      "2018-06-23 14:35:06 : 3,800,000 : 0 : 32%\n",
      "2020-12-12 23:22:03 : 3,900,000 : 0 : 33%\n",
      "2021-01-29 02:20:07 : 4,000,000 : 0 : 34%\n",
      "2021-01-29 08:40:25 : 4,100,000 : 0 : 35%\n",
      "2021-01-29 18:31:22 : 4,200,000 : 0 : 35%\n",
      "2021-01-30 03:48:28 : 4,300,000 : 0 : 36%\n",
      "2021-01-30 17:55:31 : 4,400,000 : 0 : 37%\n",
      "2021-01-31 18:39:05 : 4,500,000 : 0 : 38%\n",
      "2021-02-01 20:56:24 : 4,600,000 : 0 : 39%\n",
      "2021-02-03 14:46:50 : 4,700,000 : 0 : 39%\n",
      "2021-02-04 19:04:19 : 4,800,000 : 0 : 39%\n",
      "2021-02-06 05:20:26 : 4,900,000 : 0 : 40%\n",
      "2021-02-07 17:13:52 : 5,000,000 : 0 : 41%\n",
      "2021-02-08 13:52:59 : 5,100,000 : 0 : 42%\n",
      "2021-02-09 16:57:59 : 5,200,000 : 0 : 43%\n",
      "2021-02-11 09:53:12 : 5,300,000 : 0 : 44%\n",
      "2021-02-13 22:50:54 : 5,400,000 : 0 : 45%\n",
      "2021-02-16 02:54:37 : 5,500,000 : 0 : 46%\n",
      "2021-02-19 09:38:19 : 5,600,000 : 0 : 46%\n",
      "2021-02-25 00:14:23 : 5,700,000 : 0 : 47%\n",
      "2021-03-05 21:13:54 : 5,800,000 : 0 : 48%\n",
      "2021-03-15 06:00:55 : 5,900,000 : 0 : 48%\n",
      "2021-03-29 16:51:23 : 6,000,000 : 0 : 49%\n",
      "2021-04-13 16:23:40 : 6,100,000 : 0 : 50%\n",
      "2021-04-15 22:00:26 : 6,200,000 : 0 : 51%\n",
      "2021-04-16 13:49:14 : 6,300,000 : 0 : 51%\n",
      "2021-04-17 03:40:14 : 6,400,000 : 0 : 52%\n",
      "2021-04-18 05:39:54 : 6,500,000 : 0 : 53%\n",
      "2021-04-19 13:33:06 : 6,600,000 : 0 : 54%\n",
      "2021-04-20 10:33:26 : 6,700,000 : 0 : 55%\n",
      "2021-04-21 01:34:06 : 6,800,000 : 0 : 56%\n",
      "2021-04-22 12:16:38 : 6,900,000 : 0 : 56%\n",
      "2021-04-23 14:50:28 : 7,000,000 : 0 : 57%\n",
      "2021-04-25 17:59:33 : 7,100,000 : 0 : 58%\n",
      "2021-04-28 13:05:13 : 7,200,000 : 0 : 59%\n",
      "2021-05-01 03:19:53 : 7,300,000 : 0 : 59%\n",
      "2021-05-03 06:06:51 : 7,400,000 : 0 : 60%\n",
      "2021-05-04 13:42:57 : 7,500,000 : 0 : 61%\n",
      "2021-05-05 04:35:50 : 7,600,000 : 0 : 61%\n",
      "2021-05-05 20:45:01 : 7,700,000 : 0 : 62%\n",
      "2021-05-06 22:38:15 : 7,800,000 : 0 : 63%\n",
      "2021-05-07 23:50:37 : 7,900,000 : 0 : 64%\n",
      "2021-05-08 20:58:55 : 8,000,000 : 0 : 65%\n",
      "2021-05-09 05:19:58 : 8,100,000 : 0 : 66%\n",
      "2021-05-09 18:30:58 : 8,200,000 : 0 : 66%\n",
      "2021-05-10 19:03:49 : 8,300,000 : 0 : 67%\n",
      "2021-05-11 22:15:24 : 8,400,000 : 0 : 68%\n",
      "2021-05-13 03:56:52 : 8,500,000 : 0 : 69%\n",
      "2021-05-14 07:12:20 : 8,600,000 : 0 : 70%\n",
      "2021-05-16 00:51:18 : 8,700,000 : 0 : 71%\n",
      "2021-05-18 03:01:16 : 8,800,000 : 0 : 71%\n",
      "2021-05-19 19:32:33 : 8,900,000 : 0 : 71%\n",
      "2021-05-21 21:50:28 : 9,000,000 : 0 : 72%\n",
      "2021-05-24 15:09:46 : 9,100,000 : 0 : 73%\n",
      "2021-05-27 20:17:51 : 9,200,000 : 0 : 74%\n",
      "2021-06-01 03:36:50 : 9,300,000 : 0 : 75%\n",
      "2021-06-04 10:56:05 : 9,400,000 : 0 : 76%\n",
      "2021-06-08 19:49:57 : 9,500,000 : 0 : 76%\n",
      "2021-06-15 08:47:02 : 9,600,000 : 0 : 77%\n",
      "2021-06-21 18:50:16 : 9,700,000 : 0 : 78%\n",
      "2021-06-25 20:13:58 : 9,800,000 : 0 : 79%\n",
      "2021-07-05 20:53:49 : 9,900,000 : 0 : 80%\n",
      "2021-07-16 16:43:02 : 10,000,000 : 0 : 81%\n",
      "2021-07-27 10:56:49 : 10,100,000 : 0 : 82%\n",
      "2021-08-10 12:00:08 : 10,200,000 : 0 : 82%\n",
      "2021-08-21 12:39:47 : 10,300,000 : 0 : 83%\n",
      "2021-09-04 02:40:21 : 10,400,000 : 0 : 84%\n",
      "2021-09-20 21:20:52 : 10,500,000 : 0 : 85%\n",
      "2021-10-08 17:07:26 : 10,600,000 : 0 : 86%\n",
      "2021-10-25 03:56:09 : 10,700,000 : 0 : 87%\n",
      "2021-11-04 23:22:20 : 10,800,000 : 0 : 87%\n",
      "2021-11-16 02:20:58 : 10,900,000 : 0 : 87%\n",
      "2021-12-01 00:17:53 : 11,000,000 : 0 : 88%\n",
      "2021-12-14 04:16:22 : 11,100,000 : 0 : 89%\n",
      "2021-12-26 19:44:36 : 11,200,000 : 0 : 90%\n",
      "2022-01-11 11:34:27 : 11,300,000 : 0 : 90%\n",
      "2022-01-25 08:25:57 : 11,400,000 : 0 : 91%\n",
      "2022-02-11 18:47:03 : 11,500,000 : 0 : 92%\n",
      "2022-03-22 03:34:05 : 11,600,000 : 0 : 92%\n",
      "2022-04-29 06:49:57 : 11,700,000 : 0 : 93%\n",
      "2022-06-11 04:24:09 : 11,800,000 : 0 : 94%\n",
      "2022-08-31 00:53:57 : 11,900,000 : 0 : 95%\n",
      "2022-11-24 13:42:49 : 12,000,000 : 0 : 96%\n",
      "2023-04-15 16:06:51 : 12,100,000 : 0 : 96%\n",
      "2024-02-21 18:54:45 : 12,200,000 : 0 : 97%\n",
      "2024-05-14 17:42:23 : 12,300,000 : 0 : 98%\n",
      "2024-11-13 03:15:13 : 12,400,000 : 0 : 99%\n",
      "2024-12-12 00:02:41 : 12,500,000 : 0 : 100%\n",
      "Complete : 12,536,734 : 0\n"
     ]
    }
   ],
   "source": [
    "# this converts a zst file to csv\n",
    "#\n",
    "# it's important to note that the resulting file will likely be quite large\n",
    "# and you probably won't be able to open it in excel or another csv reader\n",
    "#\n",
    "# arguments are inputfile, outputfile, fields\n",
    "# call this like\n",
    "# python to_csv.py wallstreetbets_submissions.zst wallstreetbets_submissions.csv author,selftext,title\n",
    "\n",
    "import zstandard\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import logging.handlers\n",
    "\n",
    "\n",
    "# put the path to the input file\n",
    "input_file_path = \"/home/jesse/Downloads/dogecoin_comments.zst\"\n",
    "# put the path to the output file, with the csv extension\n",
    "output_file_path = \"/home/jesse/Downloads/dogecoin_comments.csv\"\n",
    "# if you want a custom set of fields, put them in the following list. If you leave it empty the script will use a default set of fields\n",
    "fields = []\n",
    "\n",
    "log = logging.getLogger(\"bot\")\n",
    "log.setLevel(logging.DEBUG)\n",
    "log.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "def read_and_decode(reader, chunk_size, max_window_size, previous_chunk=None, bytes_read=0):\n",
    "\tchunk = reader.read(chunk_size)\n",
    "\tbytes_read += chunk_size\n",
    "\tif previous_chunk is not None:\n",
    "\t\tchunk = previous_chunk + chunk\n",
    "\ttry:\n",
    "\t\treturn chunk.decode()\n",
    "\texcept UnicodeDecodeError:\n",
    "\t\tif bytes_read > max_window_size:\n",
    "\t\t\traise UnicodeError(f\"Unable to decode frame after reading {bytes_read:,} bytes\")\n",
    "\t\treturn read_and_decode(reader, chunk_size, max_window_size, chunk, bytes_read)\n",
    "\n",
    "\n",
    "def read_lines_zst(file_name):\n",
    "\twith open(file_name, 'rb') as file_handle:\n",
    "\t\tbuffer = ''\n",
    "\t\treader = zstandard.ZstdDecompressor(max_window_size=2**31).stream_reader(file_handle)\n",
    "\t\twhile True:\n",
    "\t\t\tchunk = read_and_decode(reader, 2**27, (2**29) * 2)\n",
    "\t\t\tif not chunk:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tlines = (buffer + chunk).split(\"\\n\")\n",
    "\n",
    "\t\t\tfor line in lines[:-1]:\n",
    "\t\t\t\tyield line, file_handle.tell()\n",
    "\n",
    "\t\t\tbuffer = lines[-1]\n",
    "\t\treader.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tif len(sys.argv) >= 3:\n",
    "\t\tinput_file_path = sys.argv[1]\n",
    "\t\toutput_file_path = sys.argv[2]\n",
    "\t\tfields = sys.argv[3].split(\",\")\n",
    "\n",
    "\tis_submission = \"submission\" in input_file_path\n",
    "\tif not len(fields):\n",
    "\t\tif is_submission:\n",
    "\t\t\tfields = [\"author\",\"title\",\"score\",\"created\",\"link\",\"text\",\"url\"]\n",
    "\t\telse:\n",
    "\t\t\tfields = [\"author\",\"score\",\"created\",\"link\",\"body\"]\n",
    "\n",
    "\tfile_size = os.stat(input_file_path).st_size\n",
    "\tfile_lines, bad_lines = 0, 0\n",
    "\tline, created = None, None\n",
    "\toutput_file = open(output_file_path, \"w\", encoding='utf-8', newline=\"\")\n",
    "\twriter = csv.writer(output_file)\n",
    "\twriter.writerow(fields)\n",
    "\ttry:\n",
    "\t\tfor line, file_bytes_processed in read_lines_zst(input_file_path):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tobj = json.loads(line)\n",
    "\t\t\t\toutput_obj = []\n",
    "\t\t\t\tfor field in fields:\n",
    "\t\t\t\t\tif field == \"created\":\n",
    "\t\t\t\t\t\tvalue = datetime.fromtimestamp(int(obj['created_utc'])).strftime(\"%Y-%m-%d %H:%M\")\n",
    "\t\t\t\t\telif field == \"link\":\n",
    "\t\t\t\t\t\tif 'permalink' in obj:\n",
    "\t\t\t\t\t\t\tvalue = f\"https://www.reddit.com{obj['permalink']}\"\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tvalue = f\"https://www.reddit.com/r/{obj['subreddit']}/comments/{obj['link_id'][3:]}/_/{obj['id']}/\"\n",
    "\t\t\t\t\telif field == \"author\":\n",
    "\t\t\t\t\t\tvalue = f\"u/{obj['author']}\"\n",
    "\t\t\t\t\telif field == \"text\":\n",
    "\t\t\t\t\t\tif 'selftext' in obj:\n",
    "\t\t\t\t\t\t\tvalue = obj['selftext']\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tvalue = \"\"\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tvalue = obj[field]\n",
    "\n",
    "\t\t\t\t\toutput_obj.append(str(value).encode(\"utf-8\", errors='replace').decode())\n",
    "\t\t\t\twriter.writerow(output_obj)\n",
    "\n",
    "\t\t\t\tcreated = datetime.utcfromtimestamp(int(obj['created_utc']))\n",
    "\t\t\texcept json.JSONDecodeError as err:\n",
    "\t\t\t\tbad_lines += 1\n",
    "\t\t\tfile_lines += 1\n",
    "\t\t\tif file_lines % 100000 == 0:\n",
    "\t\t\t\tlog.info(f\"{created.strftime('%Y-%m-%d %H:%M:%S')} : {file_lines:,} : {bad_lines:,} : {(file_bytes_processed / file_size) * 100:.0f}%\")\n",
    "\texcept KeyError as err:\n",
    "\t\tlog.info(f\"Object has no key: {err}\")\n",
    "\t\tlog.info(line)\n",
    "\texcept Exception as err:\n",
    "\t\tlog.info(err)\n",
    "\t\tlog.info(line)\n",
    "\n",
    "\toutput_file.close()\n",
    "\tlog.info(f\"Complete : {file_lines:,} : {bad_lines:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364a2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已保存筛选后的数据到：/home/jesse/Projects/myprojs/MT_1/01_Data_Collection/Dogecoin_CSV/Dogecoin_Reddit_2021-01-01_to_2022-12-31.csv\n",
      "共保留评论数：8134067\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 原始 CSV 路径\n",
    "input_path = \"/home/jesse/Projects/myprojs/MT_1/01_Data_Collection/Dogecoin_CSV/dogecoin_comments.csv\"\n",
    "\n",
    "# 目标输出路径\n",
    "output_path = \"/home/jesse/Projects/myprojs/MT_1/01_Data_Collection/Dogecoin_CSV/Dogecoin_Reddit_2021-01-01_to_2022-12-31.csv\"\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# 将 created 字段转换为 datetime 类型\n",
    "df['created'] = pd.to_datetime(df['created'], errors='coerce')\n",
    "\n",
    "# 筛选日期范围\n",
    "start_date = pd.Timestamp('2021-01-01')\n",
    "end_date = pd.Timestamp('2022-12-31 23:59:59')\n",
    "filtered_df = df[(df['created'] >= start_date) & (df['created'] <= end_date)]\n",
    "\n",
    "# 保存过滤后的数据\n",
    "filtered_df.to_csv(output_path, index=False)\n",
    "print(f\"✅ 已保存筛选后的数据到：{output_path}\")\n",
    "print(f\"共保留评论数：{len(filtered_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b6ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
